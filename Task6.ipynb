{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "576065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numba\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7e98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet1 = []\n",
    "for file in os.listdir('Task6/TestSet1'): \n",
    "    TestSet1.append(cv2.cvtColor(np.asarray(Image.open(f'Task6/TestSet1/{file}')), cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fdc1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet2 = []\n",
    "for file in os.listdir('Task6/TestSet2'): \n",
    "    TestSet2.append(cv2.cvtColor(np.asarray(Image.open(f'Task6/TestSet2/{file}')), cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3341358",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def fht(img, upper_border, lower_border):\n",
    "    n, m = img.shape[0], img.shape[1] \n",
    "    result = np.zeros((n, lower_border - upper_border))\n",
    "    if lower_border - upper_border == 1:\n",
    "        result[:, 0] = img[:, upper_border]\n",
    "        return result\n",
    "    middle = (lower_border + upper_border) // 2\n",
    "    upper_half = fht(img, upper_border, middle)\n",
    "    lower_half = fht(img, middle, lower_border)\n",
    "    for shift in range(lower_border - upper_border):\n",
    "        for i in range(n):\n",
    "            result[i, shift] = upper_half[i, shift // 2] + lower_half[(i + shift // 2 + shift % 2) % n, shift // 2]\n",
    "    return result\n",
    "\n",
    "def fht_arbitrary_shape(img):\n",
    "    new_xshape = 2 ** math.ceil(math.log2(img.shape[1])) #добавляем паддинг для того, чтобы размер изображения стал степенью двойки\n",
    "    new_img = np.pad(img, [[0, 0], \n",
    "                          [(new_xshape - img.shape[1]) // 2, (new_xshape - img.shape[1]) // 2 + (new_xshape - img.shape[1]) % 2],\n",
    "                          ], mode='empty')\n",
    "    result = fht(new_img, 0, new_xshape)\n",
    "    return new_img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155a5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(img):\n",
    "    x = cv2.Sobel(img,cv2.CV_16S,1,0)  #применяем фильтр Собеля\n",
    "    y = cv2.Sobel(img,cv2.CV_16S,0,1)  \n",
    "\n",
    "    absX = cv2.convertScaleAbs(x)\n",
    "    absY = cv2.convertScaleAbs(y) \n",
    "  \n",
    "    dst = cv2.addWeighted(absX,0.5,absY,0.5,0)  \n",
    "    \n",
    "    rot = fht_arbitrary_shape(dst), fht_arbitrary_shape(np.flip(dst, axis=1))\n",
    "    rotation_is_clockwise = np.argmax([np.var(rot[0][1], axis=0).max(), np.var(rot[1][1], axis=0).max()])\n",
    "    rotation_angle = math.atan(np.argmax(np.var(rot[rotation_is_clockwise][1]\n",
    "                                                , axis=0)) / rot[rotation_is_clockwise][1].shape[1]) * 180 / math.pi\n",
    "    return ndimage.rotate(img, (-1)**rotation_is_clockwise * rotation_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1936789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(anchors):\n",
    "    if len(anchors) == 0:\n",
    "        return []\n",
    "    x = anchors[:, :, :, 0]\n",
    "    y = anchors[:, :, :, 1]\n",
    "    w, h = np.max(x) - np.min(x), np.max(y) - np.min(y)\n",
    "    w, h = max(w,h), max(w,h)\n",
    "    box = [np.min(x), np.min(y), w, h]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6a66bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(img, boxes):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    for box in boxes:\n",
    "        plt.plot([box[0], box[0] + box[2], box[0] + box[2], box[0], box[0]], \n",
    "                 [box[1], box[1], box[1] + box[3], box[1] + box[3], box[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43fc1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_square(anchor, eps):\n",
    "    x = anchor[:, :, 0]\n",
    "    y = anchor[:, :, 1]\n",
    "    return abs(1 - (np.max(x) - np.min(x)) / (np.max(y) - np.min(y))) < eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f0e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anchor_clusters(anchors, eps):\n",
    "    if len(anchors) == 0:\n",
    "        return []\n",
    "    clusters = []\n",
    "    x = anchors[:, :, :, 0]\n",
    "    y = anchors[:, :, :, 1]\n",
    "    for i in range(len(anchors)):\n",
    "        for j in range(i):\n",
    "            if abs(1 - np.min(x[i]) / np.min(x[j])) < eps or abs(1 - np.min(y[i]) / np.min(y[j])) < eps or \\\n",
    "                abs(1 - (np.max(x[i]) - np.min(x[j])) / (np.max(y[i]) - np.min(y[j]))) < eps:\n",
    "                clusters.append([i, j])\n",
    "    for i in range(len(anchors)):\n",
    "        for j in range(len(clusters)):\n",
    "            if i in clusters[j]:\n",
    "                continue\n",
    "            for k in clusters[j]:\n",
    "                if abs(1 - np.min(x[i]) / np.min(x[k])) < eps or abs(1 - np.min(y[i]) / np.min(y[k])) < eps or \\\n",
    "                abs(1 - (np.max(x[i]) - np.min(x[k])) / (np.max(y[i]) - np.min(y[k]))) < eps:\n",
    "                    clusters[j] += [i]\n",
    "                    break\n",
    "    return [[anchors[k] for k in cluster] for cluster in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b878474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_qr_codes(img):\n",
    "    img = rotate_image(img)\n",
    "    thresh_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    cnts, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    anchors = []\n",
    "    for i, cnt in enumerate(cnts):\n",
    "        if hierarchy[0][i][2] > 0 and hierarchy[0][i][3] > 0 and hierarchy[0][hierarchy[0][i][2]][2] > 0:\n",
    "            cnt = cv2.approxPolyDP(cnt, 10, closed=True)\n",
    "            if cnt.shape[0] == 4:\n",
    "                anchors.append(cnt)\n",
    "    clusters = make_anchor_clusters(np.array(anchors)[[is_square(anchor, 5e-1) for anchor in anchors]], 1e-2)\n",
    "    boxes = []\n",
    "    for cluster in clusters:\n",
    "        boxes.append(get_boxes(np.array(cluster)))\n",
    "    return (img, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in tqdm(list(enumerate(TestSet1))):\n",
    "    img, boxes = find_qr_codes(image)    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for box in boxes:\n",
    "        plt.plot([box[0], box[0] + box[2], box[0] + box[2], box[0], box[0]], \n",
    "                 [box[1], box[1], box[1] + box[3], box[1] + box[3], box[1]])\n",
    "    plt.savefig(f'Task_6_Results/TestSet1/img_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748635ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in tqdm(list(enumerate(TestSet2))):\n",
    "    img, boxes = find_qr_codes(image)    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for box in boxes:\n",
    "        plt.plot([box[0], box[0] + box[2], box[0] + box[2], box[0], box[0]], \n",
    "                 [box[1], box[1], box[1] + box[3], box[1] + box[3], box[1]])\n",
    "    plt.savefig(f'Task_6_Results/TestSet2/img_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a16d2",
   "metadata": {},
   "source": [
    "Описание алгоритма: <br>\n",
    "    При помощи одного из реализованных ранее домашних заданий выравниваем изображение вдоль осей <br>\n",
    "    С помощью opencv находим контуры фигур и иерархию контуров <br>\n",
    "    Апроксимируем найденные контуры более простыми кривыми и ищем кривые приближенно похожие на квадраты <br>\n",
    "    Ищем с помощью найденных контуров и иерархии \"опорные\" точки qr-кодов <br>\n",
    "    Разбиваем найденные точки по qr-кодам исходя из их положения, если есть 2 и более подходящие точки в данном множестве, отрисовываем bounding-box данного qr-кода <br><br>\n",
    "\n",
    "В среднем на один прогон изображений из одного из TestSet'ов тратится ~ 7.5 минут. Итого время работы алгоритма ~9.6 секунд на изображение. <br><br>\n",
    "\n",
    "Для 1 множества имеем 19 правильных срабатываний и 2 неправильных, всего кодов на изображениях 48, т.е. precision ~90.5% и recall ~39.6% <br>\n",
    "Для 2 множества имеем 12 правильных срабатываний и 14 неправильных, всего кодов на изображениях 48, т.е. precision ~46.2% и recall ~25% <br>\n",
    "Результат, конечно, далеко не самый лучший, но зато почти своими руками:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee5205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
